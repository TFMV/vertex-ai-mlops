{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1104e83",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Vertex+AI+Vector+Search.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Vertex%2520AI%2520Vector%2520Search.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {},
   "source": [
    "# Retrieval - Vertex AI Vector Search\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).\n",
    "\n",
    "**Vertex AI Vector Search For Storage, Indexing, And Search**\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering enhanced features such as:\n",
    "\n",
    "- Support for sparse embeddings, including those used for keyword searches.\n",
    "- Hybrid search capabilities that combine dense and sparse embeddings.\n",
    "- Batch and streaming indexing options to match update latency requirements.\n",
    "- Inclusion of vector attributes (metadata) that can be used for filtering searches (allowlisting and denylisting).\n",
    "- Crowding attributes to limit the number of responses within groups.\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-vertex-vector-search'\n",
    "\n",
    "# GCS storage bucket name\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Vertex AI Vector Search Names\n",
    "VS_INDEX_NAME = f\"{SERIES}-{EXPERIMENT}\"\n",
    "VS_ENDPOINT_NAME = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "# gcs client\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs client\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745dc92-0000-418f-a914-3bd4fa49cf5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval With Vertex AI Vector Search\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering many enhanced functions, like streaming inserts of new embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301f984-bbe8-4e0f-b30f-dcbc620fe4aa",
   "metadata": {},
   "source": [
    "### Prepare Input Data In GCS\n",
    "\n",
    "A batch input for Vertex AI Vector Search are sourced from GCS directory with structure:\n",
    "```\n",
    "batch_root/\n",
    "├── features_1.csv\n",
    "├── features_2.csv\n",
    "└── delete/\n",
    "    └── deletes_1.txt\n",
    "```\n",
    "Where each `features*` files is `.csv`, `.json`, or `.avro` file of input feature data.  The `delete` folder has `.txt` files of record IDs to remove from the the index.  Each batch job will have a batch root folder like this.\n",
    "\n",
    "The `features` files have structs of input information for each input and requires a value for `id` and for `embedding` and/or `sparse_embedding`.  The `sparse_embedding` can be great for keyword search and hybrid search.  The example below focuses on embeddings which are also called dense embeddings.\n",
    "\n",
    "The `features` files can also have optional `restricts` with  `namespace` and `allow` tokens for use in filtering and crowding during search.  These will be used in the example below.\n",
    "\n",
    "**Reference:**\n",
    "- [Input data format and structure](https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure)\n",
    "- [Filter vector matches](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d49296-f176-4a83-8914-b7a1e2f522f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inside_vs_data = [\n",
    "    dict(\n",
    "        id = chunk['instance']['chunk_id'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values'],\n",
    "        restricts = [\n",
    "            dict(\n",
    "                namespace = 'gse',\n",
    "                allow = [chunk['instance']['gse']]\n",
    "            )\n",
    "        ]\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1224402f-d59d-486e-b0f8-b0d7b170c382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outside_vs_data = {}\n",
    "for chunk in chunks:\n",
    "    outside_vs_data[chunk['instance']['chunk_id']] = chunk['instance']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb70841-1c8d-4cdc-adb8-bda90602bea6",
   "metadata": {},
   "source": [
    "#### Save To GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6119ba51-bc70-426a-866b-bd7f0c075916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, applied-genai/retrieval-vertex-vector-search/batches/initial/feature.json, 1729196214188520>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/batches/initial/feature.json')\n",
    "jsonl_data = '\\n'.join(json.dumps(row) for row in inside_vs_data)\n",
    "blob.upload_from_string(jsonl_data, content_type = 'application/json')\n",
    "list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dad38a-6f8c-43fe-8774-1e5e58844f7b",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index\n",
    "\n",
    "Before deploying an index for use on an endpoint with Vertex AI Vector Search, you first create the index and load the data.  The workflow here will create and load the data to two different indexes: one for treeAH approximate nearest neighbors search, and one for brute force full search.  Indexes can be created for batch updates or streaming updates.\n",
    "\n",
    "**Reference:**\n",
    "- [Create and managed your index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index)\n",
    "- [Index configuration parameters](https://cloud.google.com/vertex-ai/docs/vector-search/configuring-indexes)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndex`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2867a-8070-42ef-909e-44f8565c550b",
   "metadata": {},
   "source": [
    "#### Create Empty Indexes\n",
    "\n",
    "Check for the index and if missing create it:\n",
    "- a tree ah index for approximation nearest neightbors search\n",
    "- a brute force index for verifying results in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11da6e43-cd7b-4dfe-9c97-839a43d97a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-tree-ah\"')\n",
    "if len(check) > 0:\n",
    "    vs_index_tree_ah = check[0]\n",
    "else:\n",
    "    vs_index_tree_ah = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name = VS_INDEX_NAME + '-tree-ah',\n",
    "        dimensions = len(question_embedding),\n",
    "        approximate_neighbors_count = 20,\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        leaf_node_embedding_count = 250,\n",
    "        leaf_nodes_to_search_percent = 10,\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28b6af7e-8955-4be0-909c-74ee90604c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-brute-force\"')\n",
    "if len(check) > 0:\n",
    "    vs_index_brute_force = check[0]\n",
    "else:\n",
    "    vs_index_brute_force = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name = VS_INDEX_NAME + '-brute-force',\n",
    "        dimensions = len(question_embedding),\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744d06d-f95d-4651-b53a-e19c008181ae",
   "metadata": {},
   "source": [
    "#### Load Data To Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b44ff-3fcd-4445-b267-0024bac1a23b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/2418270272177045504/operations/6994365820767830016\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7f0bd6b78fd0> \n",
       "resource name: projects/1026793852137/locations/us-central1/indexes/2418270272177045504"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_tree_ah.update_embeddings(\n",
    "    contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "    is_complete_overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf00bd-6990-44a3-a1c4-1c7651aab8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/1855742531220799488/operations/1405961633154465792\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7f0bd6b79ba0> \n",
       "resource name: projects/1026793852137/locations/us-central1/indexes/1855742531220799488"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_brute_force.update_embeddings(\n",
    "    contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "    is_complete_overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261294-4b73-49fc-bb6a-8106fc193228",
   "metadata": {},
   "source": [
    "### Manage An Index\n",
    "\n",
    "Similar to loading data to the indexes in the previous section, batch update can be carried out with increment data or complete overwrites.  If the indexes are set up for streaming updates the upserts can be streamed to the indexes.\n",
    "\n",
    "**Reference:**\n",
    "- [Update and rebuild index](https://cloud.google.com/vertex-ai/docs/vector-search/update-rebuild-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5727964-51c5-46ee-b8f6-da66963b5b39",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index Endpoint\n",
    "\n",
    "To make indexes available for serving nearest neighbors matches they need to be deployed to a Vertex AI Vector Search endpoints.  This section will create an endpoint (or retrieve it).  The work below creates a public endpoint but the endpoint can also be created with VPC peering or private service connect.  \n",
    "\n",
    "**Reference:**\n",
    "- [Deploy - Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public)\n",
    "- [Deploy - Private services access(VPC peering)](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc)\n",
    "- [Deploy - Private Services Connect (PSC)](https://cloud.google.com/vertex-ai/docs/vector-search/setup/private-service-connect)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7cc655b-cbd4-4577-b555-f454b0c052bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = aiplatform.MatchingEngineIndexEndpoint.list(filter=f'display_name=\"{VS_ENDPOINT_NAME}\"')\n",
    "if len(check) > 0:\n",
    "    vs_endpoint = check[0]\n",
    "else:\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name = VS_ENDPOINT_NAME,\n",
    "        public_endpoint_enabled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce35ac1-5727-4f15-b244-04f591f72c5f",
   "metadata": {},
   "source": [
    "### Deploy Indexes To Index Endpoint\n",
    "\n",
    "Check for indexes on the endpoint and if missing deploy them\n",
    "\n",
    "This is the point where computing resources are started to hosts the endpoint. Choices here and the up time of the endpoint are important considerations for performance and [costs](https://cloud.google.com/vertex-ai/pricing#vectorsearch).\n",
    "\n",
    "**Notes**\n",
    "- Machine types should chosen to support the choosen shard size (see first reference below)\n",
    "- It is recommended to have two replicas per shard\n",
    "- min_replica_count and max_replica_count default to 2 (no autoscaling)\n",
    "- if min_replica_count is not set then it defaults to 2\n",
    "- if max_replica_count is not set then it defaults to the same value as min_replica_count\n",
    "\n",
    "**Reference:**\n",
    "- [Machine type options](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#create-index)\n",
    "- [Enable Autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling)\n",
    "    - [Change autoscaling parameters for and endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#mutate-deployed-index)\n",
    "- [Deployment settings that impact performance](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "896ad94f-ea8f-4cf6-a639-f6f0e0c6f163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found index already deployed to endpoint: applied-genai-retrieval-vertex-vector-search-tree-ah\n",
      "Deploying index: applied-genai-retrieval-vertex-vector-search-brute-force\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/5646254613951676416\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n"
     ]
    }
   ],
   "source": [
    "for index in [vs_index_tree_ah, vs_index_brute_force]:\n",
    "    if index.display_name.replace('-', '_') not in [i.id for i in vs_endpoint.deployed_indexes]:\n",
    "        print(f'Deploying index: {index.display_name}')\n",
    "        vs_endpoint = vs_endpoint.deploy_index(\n",
    "            index = index,\n",
    "            deployed_index_id = index.display_name.replace('-', '_'),\n",
    "            machine_type = 'e2-standard-2',\n",
    "            min_replica_count = 2,\n",
    "            max_replica_count = 2, \n",
    "        )\n",
    "    else:\n",
    "        print(f'Found index already deployed to endpoint: {index.display_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27df7d60-3ed0-40e7-8438-f5faaa08014c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"applied_genai_retrieval_vertex_vector_search_tree_ah\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/2418270272177045504\"\n",
       "create_time {\n",
       "  seconds: 1729254606\n",
       "  nanos: 813361000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1729255422\n",
       "  nanos: 874192000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       ", id: \"applied_genai_retrieval_vertex_vector_search_brute_force\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/1855742531220799488\"\n",
       "create_time {\n",
       "  seconds: 1729255453\n",
       "  nanos: 24613000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1729255666\n",
       "  nanos: 483282000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c9bb1-6680-4b8b-a0fa-e222141864c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b029a4d-8c77-4f1f-9f83-200cd7ced1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc05d84-9a97-4494-bede-915dfa30f4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdb4bb-093b-4288-aa45-3fc59bb0950c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c09446-3196-4b61-aa61-6f5aae174c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482433a-e1fb-47bf-b04e-2f34002b1c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6cadf3-3b84-468b-91f5-b7f835296fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4e2f7-3355-41aa-bcc5-f673eb1fe990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8128d-d206-4ffa-888a-99c57bf5f61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24c5c2-c588-4aa6-90fd-3cd6b92dba01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b10b7-b914-4d4e-b674-1af5be4ed445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1332db-eb4f-4618-98d3-dad842f3e90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c698479-ef35-43b4-86cb-e2547e467e5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Simple RAG Using Vertex AI Vector Search For Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b6c2c-987c-4478-b7da-d4566750c2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10bc5c-a5d0-41de-af55-6513e0e2f13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226cad1b-18f5-4120-87e5-b6af492988ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "\n",
    "-undeploy index\n",
    "- delete endpoint\n",
    "- delete index\n",
    "- remove gcs\n",
    "\n",
    "gcs and fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df72131-c6f6-4b5b-a027-4e30b0047267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undeploy indexes created above:\n",
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'))\n",
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_brute_force.display_name.replace('-', '_'))\n",
    "\n",
    "# delete the endpoint\n",
    "#vs_endpoint.delete(force = True)\n",
    "\n",
    "# delete the indexes\n",
    "#\n",
    "\n",
    "# delete the gcs content\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
