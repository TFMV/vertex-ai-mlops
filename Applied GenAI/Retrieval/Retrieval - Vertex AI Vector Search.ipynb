{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1104e83",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FRetrieval&file=Retrieval+-+Vertex+AI+Vector+Search.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FRetrieval%2FRetrieval%2520-%2520Vertex%2520AI%2520Vector%2520Search.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Retrieval/Retrieval%20-%20Vertex%20AI%20Vector%20Search.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0e8e6-d761-4540-9d09-8f0c4ce9a020",
   "metadata": {},
   "source": [
    "# Retrieval - Vertex AI Vector Search\n",
    "\n",
    "In prior workflows, a series of documents was [processed into chunks](../Chunking/readme.md), and for each chunk, [embeddings](../Embeddings/readme.md) were created:\n",
    "\n",
    "- Process: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb)\n",
    "- Embed: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)\n",
    "\n",
    "Retrieving chunks for a query involves calculating the embedding for the query and then using similarity metrics to find relevant chunks. A thorough review of similarity matching can be found in [The Math of Similarity](../Embeddings/The%20Math%20of%20Similarity.ipynb) - use dot product! As development moves from experiment to application, the process of storing and computing similarity is migrated to a [retrieval](./readme.md) system. This workflow is part of a [series of workflows exploring many retrieval systems](./readme.md).\n",
    "\n",
    "**Vertex AI Vector Search For Storage, Indexing, And Search**\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering enhanced features such as:\n",
    "\n",
    "- Support for sparse embeddings, including those used for keyword searches.\n",
    "- Hybrid search capabilities that combine dense and sparse embeddings.\n",
    "- Batch and streaming indexing options to match update latency requirements.\n",
    "- Inclusion of vector attributes (metadata) that can be used for filtering searches (allowlisting and denylisting).\n",
    "- Crowding attributes to limit the number of responses within groups.\n",
    "\n",
    "**Use Case Data**\n",
    "\n",
    "Buying a home usually involves borrowing money from a lending institution, typically through a mortgage secured by the home's value. But how do these institutions manage the risks associated with such large loans, and how are lending standards established?\n",
    "\n",
    "In the United States, two government-sponsored enterprises (GSEs) play a vital role in the housing market:\n",
    "\n",
    "- Federal National Mortgage Association ([Fannie Mae](https://www.fanniemae.com/))\n",
    "- Federal Home Loan Mortgage Corporation ([Freddie Mac](https://www.freddiemac.com/))\n",
    "\n",
    "These GSEs purchase mortgages from lenders, enabling those lenders to offer more loans. This process also allows Fannie Mae and Freddie Mac to set standards for mortgages, ensuring they are responsible and borrowers are more likely to repay them. This system makes homeownership more affordable and stabilizes the housing market by maintaining a steady flow of liquidity for lenders and keeping interest rates controlled.\n",
    "\n",
    "However, navigating the complexities of these GSEs and their extensive servicing guides can be challenging.\n",
    "\n",
    "**Approaches**\n",
    "\n",
    "[This series](../readme.md) covers many generative AI workflows. These documents are used directly as long context for Gemini in the workflow [Long Context Retrieval With The Vertex AI Gemini API](../Generate/Long%20Context%20Retrieval%20With%20The%20Vertex%20AI%20Gemini%20API.ipynb). The workflow below uses a [retrieval](./readme.md) approach with the already generated chunks and embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be889472-69b0-416c-9cf1-edc9706fa5c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f75ba8-df50-466e-a5ec-f2a6dd88eb26",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c325515-1ea0-45cc-82d3-a1bfb1c52155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4bd7-7b47-43ef-ba14-636c955e44e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410502ee-6fe3-4624-a69a-960ad7105f10",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4dbdb83-3170-430c-b60d-3d686222a168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.69.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25374857-7d37-4c84-8cbb-a3c2fc7bb065",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7300a8-7e3a-4a08-95c0-91186237753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d09ba-9774-495f-8ced-3382bf75be8f",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9864153-66c8-43e1-ae96-1179632ccf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1ab41-cb32-4398-86dc-d30effb88a36",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe11b-9ca1-4f3e-aa78-78640ff01ec8",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2239cd-40ab-416d-bac0-0c6953d911b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa97f05-66e9-4276-b2e6-83b5a91ca50c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'retrieval-vertex-vector-search'\n",
    "\n",
    "# GCS storage bucket name\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Vertex AI Vector Search Names\n",
    "VS_INDEX_NAME = f\"{SERIES}-{EXPERIMENT}\"\n",
    "VS_ENDPOINT_NAME = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf65b-5d29-4a72-84ae-d977b9a743a6",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559f6e60-a594-4789-893b-295a8381b670",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import vertexai.language_models # for embeddings API\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "# gcs client\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fef31f-928f-45f2-a3f4-292ee242232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c07e-f064-40fb-a0ef-de6cbde5cd0a",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72f3bb-176b-4678-ba6b-df9b2de14997",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "\n",
    "# gcs client\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579282f-2723-4294-b72a-a65cc0831f44",
   "metadata": {},
   "source": [
    "---\n",
    "## Text & Embeddings For Examples\n",
    "\n",
    "This repository contains a [section for document processing (chunking)](../Chunking/readme.md) that includes an example of processing mulitple large pdfs (over 1000 pages) into chunks: [Large Document Processing - Document AI Layout Parser](../Chunking/Large%20Document%20Processing%20-%20Document%20AI%20Layout%20Parser.ipynb).  The chunks of text from that workflow are stored with this repository and loaded by another companion workflow that augments the chunks with text embeddings: [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb).\n",
    "\n",
    "The following code will load the version of the chunks that includes text embeddings and prepare it for a local example of retrival augmented generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cbe2-3ca6-4656-9e73-c0db5c63bf50",
   "metadata": {},
   "source": [
    "### Get The Documents\n",
    "\n",
    "If you are working from a clone of this notebooks [repository](https://github.com/statmike/vertex-ai-mlops) then the documents are already present. The following cell checks for the documents folder and if it is missing gets it (`git clone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4e77ed-43f7-42be-9575-6a491c0d6cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../Embeddings/files/embeddings-api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ebe7c3-e72c-4394-91c3-d60c05bc0ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Found in folder `../Embeddings/files/embeddings-api`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving documents...')\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Documents are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Documents Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e68a84-9f88-4590-9ff1-e01c8a953ccf",
   "metadata": {},
   "source": [
    "### Load The Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d04382-a74a-44ac-8824-3b46c86aa148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0000.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0001.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0002.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0003.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0004.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0005.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0006.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0007.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0008.jsonl',\n",
       " '../Embeddings/files/embeddings-api/large-files-chunk-embeddings-0009.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(f\"{local_dir}/large-files*.jsonl\")\n",
    "jsonl_files.sort()\n",
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54c6c96-6c28-49bb-80be-5d46797dfe77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r') as f:\n",
    "        chunks.extend([json.loads(line) for line in f])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70115ec-6d60-41df-b7e6-9e2e5b463b1d",
   "metadata": {},
   "source": [
    "### Review A Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc20423e-e3d6-4e90-9e98-a5248508c82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance', 'predictions', 'status'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955ea39-4ffc-4d30-b653-a5a9911f2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c17'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['instance']['chunk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3537982c-4a0e-456c-a652-19ea7507873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Selling Guide Fannie Mae Single Family\n",
      "\n",
      "## Fannie Mae Copyright Notice\n",
      "\n",
      "### Fannie Mae Copyright Notice\n",
      "\n",
      "|-|\n",
      "| Section B3-4.2, Verification of Depository Assets 402 |\n",
      "| B3-4.2-01, Verification of Deposits and Assets (05/04/2022) 403 |\n",
      "| B3-4.2-02, Depository Accounts (12/14/2022) 405 |\n",
      "| B3-4.2-03, Individual Development Accounts (02/06/2019) 408 |\n",
      "| B3-4.2-04, Pooled Savings (Community Savings Funds) (04/01/2009) 411 |\n",
      "| B3-4.2-05, Foreign Assets (05/04/2022) 411 |\n",
      "| Section B3-4.3, Verification of Non-Depository Assets 412 |\n",
      "| B3-4.3-01, Stocks, Stock Options, Bonds, and Mutual Funds (06/30/2015) 412 |\n",
      "| B3-4.3-02, Trust Accounts (04/01/2009) 413 |\n",
      "| B3-4.3-03, Retirement Accounts (06/30/2015) 414 |\n",
      "| B3-4.3-04, Personal Gifts (09/06/2023) 415 |\n",
      "| B3-4.3-05, Gifts of Equity (10/07/2020) 418 |\n",
      "| B3-4.3-06, Grants and Lender Contributions (12/14/2022) 419 |\n",
      "| B3-4.3-07, Disaster Relief Grants or Loans (04/01/2009) 423 |\n",
      "| B3-4.3-08, Employer Assistance (09/29/2015) 423 |\n",
      "| B3-4.3-09, Earnest Money Deposit (05/04/2022) 425 |\n",
      "| B3-4.3-10, Anticipated Sales Proceeds (02/23/2016) B3-4.3-11, Trade Equity (12/16/2020) 426 428 |\n",
      "| B3-4.3-12, Rent-Related Credits (08/07/2024) 429 |\n",
      "| B3-4.3-13, Sweat Equity (04/15/2014) 430 |\n",
      "| B3-4.3-14, Bridge/Swing Loans (04/01/2009) 431 |\n",
      "| B3-4.3-15, Borrowed Funds Secured by an Asset (10/30/2009) 431 |\n",
      "|  |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0]['instance']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f06293-a439-436b-bc93-cd6cd3fb4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.031277116388082504,\n",
       " 0.03056905046105385,\n",
       " 0.010865348391234875,\n",
       " 0.0623614676296711,\n",
       " 0.03228681534528732,\n",
       " 0.05066155269742012,\n",
       " 0.046544693410396576,\n",
       " 0.05509665608406067,\n",
       " -0.014074751175940037,\n",
       " 0.008380400016903877]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['predictions'][0]['embeddings']['values'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977358d-d9ea-4172-9eca-66079bb6087d",
   "metadata": {},
   "source": [
    "### Prepare Chunk Structure\n",
    "\n",
    "Make a list of dictionaries with information for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9fa708-130c-4343-b179-dbde0b09a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_chunks = [\n",
    "    dict(\n",
    "        gse = chunk['instance']['gse'],\n",
    "        chunk_id = chunk['instance']['chunk_id'],\n",
    "        content = chunk['instance']['content'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6619605-7b10-444e-a131-db06e56a4be8",
   "metadata": {},
   "source": [
    "### Query Embedding\n",
    "\n",
    "Create a query, or prompt, and get the embedding for it:\n",
    "\n",
    "Connect to models for text embeddings. Learn more about the model API:\n",
    "- [Vertex AI Text Embeddings API](../Embeddings/Vertex%20AI%20Text%20Embeddings%20API.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da5d30c-3dfb-42ba-a133-83dceb252787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Does a lender have to perform servicing functions directly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7992c26f-d058-4920-80a3-a157b88733e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = vertexai.language_models.TextEmbeddingModel.from_pretrained('text-embedding-004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6fda7-9cea-49a2-9e2f-9222d50677af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0005117303808219731,\n",
       " 0.009651427157223225,\n",
       " 0.01768726110458374,\n",
       " 0.014538003131747246,\n",
       " -0.01829824410378933,\n",
       " 0.027877431362867355,\n",
       " -0.021124685183167458,\n",
       " 0.008830446749925613,\n",
       " -0.02669006586074829,\n",
       " 0.06414774805307388]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = embedder.get_embeddings([question])[0].values\n",
    "question_embedding[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3745dc92-0000-418f-a914-3bd4fa49cf5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval With Vertex AI Vector Search\n",
    "\n",
    "[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) is a vector similarity search solution built for scale, offering many enhanced functions, like streaming inserts of new embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301f984-bbe8-4e0f-b30f-dcbc620fe4aa",
   "metadata": {},
   "source": [
    "### Prepare Input Data In GCS\n",
    "\n",
    "A batch input for Vertex AI Vector Search are sourced from GCS directory with structure:\n",
    "```\n",
    "batch_root/\n",
    "├── features_1.csv\n",
    "├── features_2.csv\n",
    "└── delete/\n",
    "    └── deletes_1.txt\n",
    "```\n",
    "Where each `features*` files is `.csv`, `.json`, or `.avro` file of input feature data.  The `delete` folder has `.txt` files of record IDs to remove from the the index.  Each batch job will have a batch root folder like this.\n",
    "\n",
    "The `features` files have structs of input information for each input and requires a value for `id` and for `embedding` and/or `sparse_embedding`.  The `sparse_embedding` can be great for keyword search and hybrid search.  The example below focuses on embeddings which are also called dense embeddings.\n",
    "\n",
    "The `features` files can also have optional `restricts` with  `namespace` and `allow` tokens for use in filtering and crowding during search.  These will be used in the example below.\n",
    "\n",
    "**Reference:**\n",
    "- [Input data format and structure](https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure)\n",
    "- [Filter vector matches](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9d49296-f176-4a83-8914-b7a1e2f522f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inside_vs_data = [\n",
    "    dict(\n",
    "        id = chunk['instance']['chunk_id'],\n",
    "        embedding = chunk['predictions'][0]['embeddings']['values'],\n",
    "        restricts = [\n",
    "            dict(\n",
    "                namespace = 'gse',\n",
    "                allow = [chunk['instance']['gse']],\n",
    "                #deny = []\n",
    "            )\n",
    "        ],\n",
    "        #numeric_restricts = [],\n",
    "        crowding_tag = chunk['instance']['gse']\n",
    "    ) for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1224402f-d59d-486e-b0f8-b0d7b170c382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outside_vs_data = {}\n",
    "for chunk in chunks:\n",
    "    outside_vs_data[chunk['instance']['chunk_id']] = chunk['instance']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb70841-1c8d-4cdc-adb8-bda90602bea6",
   "metadata": {},
   "source": [
    "#### Save To GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6119ba51-bc70-426a-866b-bd7f0c075916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, applied-genai/retrieval-vertex-vector-search/batches/initial/feature.json, 1729272505081932>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/batches/initial/feature.json')\n",
    "jsonl_data = '\\n'.join(json.dumps(row) for row in inside_vs_data)\n",
    "blob.upload_from_string(jsonl_data, content_type = 'application/json')\n",
    "list(bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dad38a-6f8c-43fe-8774-1e5e58844f7b",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index\n",
    "\n",
    "Before deploying an index for use on an endpoint with Vertex AI Vector Search, you first create the index and load the data.  The workflow here will create and load the data to two different indexes: one for treeAH approximate nearest neighbors search, and one for brute force full search.  Indexes can be created for batch updates or streaming updates.\n",
    "\n",
    "**Reference:**\n",
    "- [Create and managed your index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index)\n",
    "- [Index configuration parameters](https://cloud.google.com/vertex-ai/docs/vector-search/configuring-indexes)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndex`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2867a-8070-42ef-909e-44f8565c550b",
   "metadata": {},
   "source": [
    "#### Create Empty Indexes\n",
    "\n",
    "Check for the index and if missing create it:\n",
    "- a tree ah index for approximation nearest neightbors search\n",
    "- a brute force index for verifying results in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11da6e43-cd7b-4dfe-9c97-839a43d97a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index ...\n",
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/5750933996431212544/operations/5446618486719643648\n",
      "MatchingEngineIndex created. Resource name: projects/1026793852137/locations/us-central1/indexes/5750933996431212544\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/1026793852137/locations/us-central1/indexes/5750933996431212544')\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-tree-ah\"')\n",
    "if len(check) > 0:\n",
    "    print('Retrieved existing index with same name.')\n",
    "    vs_index_tree_ah = check[0]\n",
    "else:\n",
    "    print('Creating index ...')\n",
    "    vs_index_tree_ah = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name = VS_INDEX_NAME + '-tree-ah',\n",
    "        dimensions = len(question_embedding),\n",
    "        approximate_neighbors_count = 20,\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        leaf_node_embedding_count = 250,\n",
    "        leaf_nodes_to_search_percent = 10,\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28b6af7e-8955-4be0-909c-74ee90604c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index ...\n",
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/2515097664165511168/operations/2684504540257976320\n",
      "MatchingEngineIndex created. Resource name: projects/1026793852137/locations/us-central1/indexes/2515097664165511168\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/1026793852137/locations/us-central1/indexes/2515097664165511168')\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndex.list(filter=f'display_name=\"{VS_INDEX_NAME}-brute-force\"')\n",
    "if len(check) > 0:\n",
    "    print('Retrieved existing index with same name.')\n",
    "    vs_index_brute_force = check[0]\n",
    "else:\n",
    "    print('Creating index ...')\n",
    "    vs_index_brute_force = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name = VS_INDEX_NAME + '-brute-force',\n",
    "        dimensions = len(question_embedding),\n",
    "        distance_measure_type = 'DOT_PRODUCT_DISTANCE',\n",
    "        index_update_method = 'BATCH_METHOD',\n",
    "        shard_size = 'SHARD_SIZE_SMALL'\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744d06d-f95d-4651-b53a-e19c008181ae",
   "metadata": {},
   "source": [
    "#### Load Data To Index\n",
    "\n",
    "Check to see if data is already loaded and if missing then load as a complete overwrite:\n",
    "\n",
    "**Note:** This can be a lengthy operation.  It is recommended to review the progress in the Vertex AI Console section for Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f60990f3-fe2d-4ea5-ba63-2634360b2544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shardsCount': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_tree_ah.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55e73079-acb6-4177-b057-54fde25bb9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shardsCount': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_brute_force.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ce275e2-3136-4250-ab6c-88f07d74bbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/5750933996431212544\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/5750933996431212544/operations/566968290463711232\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/5750933996431212544\n"
     ]
    }
   ],
   "source": [
    "if 'vectorsCount' not in vs_index_tree_ah.to_dict()['indexStats']:\n",
    "    print('Loading Embeddings...')\n",
    "    vs_index_tree_ah.update_embeddings(\n",
    "        contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "        is_complete_overwrite = True\n",
    "    )\n",
    "    vs_index_tree_ah = aiplatform.MatchingEngineIndex(index_name = vs_index_tree_ah.name)\n",
    "else:\n",
    "    print('Embeddings already loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa61d578-db37-4ae0-9826-1423523365ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Updating MatchingEngineIndex index: projects/1026793852137/locations/us-central1/indexes/2515097664165511168\n",
      "Update MatchingEngineIndex index backing LRO: projects/1026793852137/locations/us-central1/indexes/2515097664165511168/operations/6070367035110457344\n",
      "MatchingEngineIndex index Updated. Resource name: projects/1026793852137/locations/us-central1/indexes/2515097664165511168\n"
     ]
    }
   ],
   "source": [
    "if 'vectorsCount' not in vs_index_brute_force.to_dict()['indexStats']:\n",
    "    print('Loading Embeddings...')\n",
    "    vs_index_brute_force.update_embeddings(\n",
    "        contents_delta_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/batches/initial',\n",
    "        is_complete_overwrite = True\n",
    "    )\n",
    "    vs_index_brute_force = aiplatform.MatchingEngineIndex(index_name = vs_index_brute_force.name)\n",
    "else:\n",
    "    print('Embeddings already loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e143963a-741d-499e-89c5-b0e212c3eb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorsCount': '9040', 'shardsCount': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_tree_ah.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20e992e-d66f-4d1f-9d5e-9c5b2a6051d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorsCount': '9040', 'shardsCount': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_index_brute_force.to_dict()['indexStats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261294-4b73-49fc-bb6a-8106fc193228",
   "metadata": {},
   "source": [
    "### Manage An Index\n",
    "\n",
    "Similar to loading data to the indexes in the previous section, batch update can be carried out with incremental data or complete overwrites.  If the indexes are set up for streaming updates the upserts can be streamed to the indexes.\n",
    "\n",
    "**Reference:**\n",
    "- [Update and rebuild index](https://cloud.google.com/vertex-ai/docs/vector-search/update-rebuild-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5727964-51c5-46ee-b8f6-da66963b5b39",
   "metadata": {},
   "source": [
    "### Create/Retrieve An Index Endpoint\n",
    "\n",
    "To make indexes available for serving nearest neighbors matches they need to be deployed to a Vertex AI Vector Search endpoints.  This section will create an endpoint (or retrieve it).  The work below creates a public endpoint but the endpoint can also be created with VPC peering or private service connect.  \n",
    "\n",
    "**Reference:**\n",
    "- [Deploy - Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public)\n",
    "- [Deploy - Private services access(VPC peering)](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc)\n",
    "- [Deploy - Private Services Connect (PSC)](https://cloud.google.com/vertex-ai/docs/vector-search/setup/private-service-connect)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7cc655b-cbd4-4577-b555-f454b0c052bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreived exiting endpoint with same name.\n"
     ]
    }
   ],
   "source": [
    "check = aiplatform.MatchingEngineIndexEndpoint.list(filter=f'display_name=\"{VS_ENDPOINT_NAME}\"')\n",
    "if len(check) > 0:\n",
    "    print('Retreived exiting endpoint with same name.')\n",
    "    vs_endpoint = check[0]\n",
    "else:\n",
    "    print('Creating endpoing...')\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name = VS_ENDPOINT_NAME,\n",
    "        public_endpoint_enabled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce35ac1-5727-4f15-b244-04f591f72c5f",
   "metadata": {},
   "source": [
    "### Deploy Indexes To Index Endpoint\n",
    "\n",
    "Check for indexes on the endpoint and if missing deploy them\n",
    "\n",
    "This is the point where computing resources are started to hosts the endpoint. Choices here and the up time of the endpoint are important considerations for performance and [costs](https://cloud.google.com/vertex-ai/pricing#vectorsearch).\n",
    "\n",
    "**Notes**\n",
    "- Machine types should chosen to support the choosen shard size (see first reference below)\n",
    "- It is recommended to have two replicas per shard\n",
    "- min_replica_count and max_replica_count default to 2 (no autoscaling)\n",
    "- if min_replica_count is not set then it defaults to 2\n",
    "- if max_replica_count is not set then it defaults to the same value as min_replica_count\n",
    "\n",
    "**Reference:**\n",
    "- [Machine type options](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#create-index)\n",
    "- [Enable Autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling)\n",
    "    - [Change autoscaling parameters for and endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#mutate-deployed-index)\n",
    "- [Deployment settings that impact performance](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "896ad94f-ea8f-4cf6-a639-f6f0e0c6f163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index: applied-genai-retrieval-vertex-vector-search-tree-ah\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072/operations/7823674665041133568\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072\n",
      "Deploying index: applied-genai-retrieval-vertex-vector-search-brute-force\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072/operations/5790299433283354624\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5622651775795331072\n"
     ]
    }
   ],
   "source": [
    "for index in [vs_index_tree_ah, vs_index_brute_force]:\n",
    "    if index.display_name.replace('-', '_') not in [i.id for i in vs_endpoint.deployed_indexes]:\n",
    "        print(f'Deploying index: {index.display_name}')\n",
    "        vs_endpoint = vs_endpoint.deploy_index(\n",
    "            index = index,\n",
    "            deployed_index_id = index.display_name.replace('-', '_'),\n",
    "            machine_type = 'e2-standard-2',\n",
    "            min_replica_count = 2,\n",
    "            max_replica_count = 2, \n",
    "        )\n",
    "        # refresh endpoint\n",
    "        vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name = vs_endpoint.resource_name\n",
    "        )\n",
    "    else:\n",
    "        print(f'Found index already deployed to endpoint: {index.display_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27df7d60-3ed0-40e7-8438-f5faaa08014c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"applied_genai_retrieval_vertex_vector_search_tree_ah\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/5750933996431212544\"\n",
       "create_time {\n",
       "  seconds: 1729279727\n",
       "  nanos: 731510000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1729281329\n",
       "  nanos: 129996000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       ", id: \"applied_genai_retrieval_vertex_vector_search_brute_force\"\n",
       "index: \"projects/1026793852137/locations/us-central1/indexes/2515097664165511168\"\n",
       "create_time {\n",
       "  seconds: 1729281332\n",
       "  nanos: 221628000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1729281546\n",
       "  nanos: 534126000\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398008e-70fe-4b99-a389-77526d08a602",
   "metadata": {},
   "source": [
    "---\n",
    "### Query Endpoint\n",
    "\n",
    "Use the endpoint to query for data and matches.\n",
    "\n",
    "**Reference:**\n",
    "- [Query Documentation](https://cloud.google.com/vertex-ai/docs/vector-search/query-index-public-endpoint)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.read_index_datapoinnts`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_read_index_datapoints)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.match`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_match)\n",
    "- [Python SDK: `aiplatform.MatchingEngineIndexEndpoint.find_neighbors`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_find_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8710008-7836-494f-a914-af38b90ee3bf",
   "metadata": {},
   "source": [
    "#### Retrieve: Embedding For Entity\n",
    "\n",
    "Retrieve the index entry for a specific id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05dbb73a-d500-43b8-8e23-8159cd0a872e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = vs_endpoint.read_index_datapoints(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    ids = ['fannie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce85ac28-0c6a-4aa1-acd8-b86b15993bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b1079ac-c973-47c7-95c6-5c3d5f697e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c40'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].datapoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fb981a6-a4f2-48b3-98db-24dd415b6738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027678849175572395,\n",
       " -0.007303171791136265,\n",
       " 0.03341332823038101,\n",
       " 0.06296615302562714,\n",
       " -0.014549952000379562]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].feature_vector[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cefbc423-3b96-4c2d-bc71-ebbd2a5e990e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"fannie\"\n",
       "]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].restricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879b367-eac9-4115-a579-8c558dbef454",
   "metadata": {},
   "source": [
    "#### Retrieve: Embeddings For Entities\n",
    "\n",
    "Retrieve the index entry for a list of specific ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a7dcf9f-947e-4a1f-b59e-40db0d437fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = vs_endpoint.read_index_datapoints(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    ids = ['fannie_part_0_c40', 'freddie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25fb0865-f004-44c7-977f-dd36eb4585ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9676359f-7b20-4286-9a09-b1da928785e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fannie_part_0_c40'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].datapoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18015629-5c04-4188-963e-334cb7641586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027678849175572395,\n",
       " -0.007303171791136265,\n",
       " 0.03341332823038101,\n",
       " 0.06296615302562714,\n",
       " -0.014549952000379562]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].feature_vector[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8010ea07-9df0-470a-a809-f1f611a6414b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"fannie\"\n",
       "]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].restricts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8257973e-2970-4eb6-9f57-094a4c5a6d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[namespace: \"gse\"\n",
       "allow_list: \"freddie\"\n",
       "]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].restricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced3159-f6c8-4588-979c-1a3d8905e516",
   "metadata": {},
   "source": [
    "#### Matches: For Entity\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4c581a7-54bb-4046-8486-a3fcc002cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    num_neighbors = 2,\n",
    "    embedding_ids = ['fannie_part_0_c40']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d5c012b-806c-4b92-8ca8-b450135f6e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c40', distance=0.999954342842102, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c39', distance=0.9096099138259888, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ad405-6c23-4937-aeb6-2dbbe02b15b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Matches: For Query Embedding\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b872543c-b3cb-4c99-b69e-9418a7ef7f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "591eac6b-858d-4903-baa1-81bb0036fdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc304e30-45cc-4dc3-9f23-cac3db793846",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fannie_part_0_c352', 0.7099842429161072),\n",
       " ('freddie_part_4_c509', 0.680526077747345)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(match.id, match.distance) for match in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858710de-ada5-4d0b-8fcf-89ee765fca13",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Same Endpoint Different Index\n",
    "\n",
    "Above two indexes were deployed to the endpoint.  This example switches to the index with brute force search:\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8d5ad8b-3952-47b3-a5dd-d7ecf1216e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_brute_force.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "460c86aa-9bc4-43d4-87f5-f436740171ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749ba5f-68bb-41c7-a6b0-65495707a9de",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Expand Search Candidates\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bcc05d84-9a97-4494-bede-915dfa30f4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    fraction_leaf_nodes_to_search_override = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cabdb4bb-093b-4288-aa45-3fc59bb0950c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51cddc3-7149-4bd3-a02f-5b23538e3b11",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Diversity of Responses\n",
    "\n",
    "Return the embedding in the response by adding `return_full_datapoint = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b482433a-e1fb-47bf-b04e-2f34002b1c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    per_crowding_attribute_neighbor_count = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f6cadf3-3b84-468b-91f5-b7f835296fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953455c2-053a-400f-ac1d-8b222a419ac3",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Limit Search Area With Allowlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffe8128d-d206-4ffa-888a-99c57bf5f61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    filter = [\n",
    "        aiplatform.matching_engine.matching_engine_index_endpoint.Namespace('gse', ['fannie'], []) # Namespece, allow list, deny list\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d24c5c2-c588-4aa6-90fd-3cd6b92dba01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='fannie_part_0_c352', distance=0.7099842429161072, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c353', distance=0.6723706722259521, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c326', distance=0.6683496832847595, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='fannie_part_0_c92', distance=0.661433756351471, sparse_distance=None, feature_vector=[], crowding_tag='1074578924770667433', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a5911-cfb6-4fab-b812-0565ed4e7a64",
   "metadata": {},
   "source": [
    "#### Matches: For Query Embedding - Limit Search Area With Denylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66210503-176a-41b8-8729-5b8fccd9ad43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = vs_endpoint.find_neighbors(\n",
    "    deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "    queries = [question_embedding],\n",
    "    num_neighbors = 4,\n",
    "    filter = [\n",
    "        aiplatform.matching_engine.matching_engine_index_endpoint.Namespace('gse', [], ['fannie']) # Namespece, allow list, deny list\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d1ac727-e1a7-42c4-bc20-6a6e264ef8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='freddie_part_4_c509', distance=0.680526077747345, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c510', distance=0.6753297448158264, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_4_c472', distance=0.6619843244552612, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='freddie_part_6_c439', distance=0.6604534983634949, sparse_distance=None, feature_vector=[], crowding_tag='-353579237037459606', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c698479-ef35-43b4-86cb-e2547e467e5b",
   "metadata": {},
   "source": [
    "---\n",
    "## Simple RAG Using Vertex AI Vector Search For Retrieval\n",
    "\n",
    "Vertex AI Vector Search returns the id's of matching entities.  The text content for these matches need be retrieved as a next step.  In the data preparation above the content of the text was stored in a dictionary locally for easy lookup:\n",
    "- `outside_vs_data = {'id': 'content', ...}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d958e7-a31f-4224-ae6d-24b08df893e8",
   "metadata": {},
   "source": [
    "### Prompt Building Function\n",
    "\n",
    "Use the matching chunks as context for the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84604a4c-9e9e-499b-b7a6-9a5d5918cb48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(question, top_n = 5):\n",
    "    # get embedding for question\n",
    "    question_embedding = embedder.get_embeddings([question])[0].values\n",
    "    \n",
    "    # get top_n matches:\n",
    "    results = vs_endpoint.find_neighbors(\n",
    "        deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'),\n",
    "        queries = [question_embedding],\n",
    "        num_neighbors = top_n\n",
    "    ) \n",
    "    matches = [(match.id, match.distance) for match in results[0]]\n",
    "\n",
    "    # construct prompt:\n",
    "    prompt = ''\n",
    "    for m, match in enumerate(matches):\n",
    "        prompt += f\"Context {m+1}:\\n{outside_vs_data[match[0]]}\\n\\n\"\n",
    "    prompt += f'Answer the following question using the provided contexts:\\n{question}'\n",
    "    \n",
    "    return matches, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1e8d32c4-d9d3-4e43-9d4b-960db0d55187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "# A3-3-03, Other Servicing Arrangements (12/15/2015)\n",
      "\n",
      "Introduction This topic provides an overview of other servicing arrangements, including: • Subservicing • General Requirements for Subservicing Arrangements • Pledge of Servicing Rights and Transfer of Interest in Servicing Income\n",
      "\n",
      "## Subservicing\n",
      "\n",
      "A lender may use other organizations to perform some or all of its servicing functions. Fannie Mae refers to these arrangements as “subservicing” arrangements, meaning that a servicer (the “subservicer”) other than the contractually responsible servicer (the “master” servicer) is performing the servicing functions. The following are not considered to be subservicing arrangements: • when a computer service bureau is used to perform accounting and reporting functions; • when the originating lender sells and assigns servicing to another lender, unless the originating lender continues to be the contractually responsible servicer.\n",
      "\n",
      "Context 2:\n",
      "# (1) Notice requirements\n",
      "\n",
      "The notice must advise the Borrower of the following: 1. The date the new Servicing Agent or Master Servicer undertakes the performance of the Servicing obligations 2. The name and address of the Servicer undertaking the performance of the Servicing obligations 3. The names and telephone numbers of the contact persons or departments where the Borrowers' inquiries relating to the transfer should be directed. (If toll-free numbers are not available, the letter must indicate that collect calls will be accepted.) Such names and telephone numbers must be provided for the party previously performing the Servicing obligations as well as the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations. 4. The date when the party previously performing the Servicing obligation will no longer collect the Borrowers' payments and when the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations will begin to collect them 5. Procedures for maintenance of automatic draft payments, if applicable. Every effort must be made to continue, without interruption, electronic payments on the Borrower's Mortgage, to the extent permitted by applicable law.\n",
      "\n",
      "Context 3:\n",
      "# (1) Notice requirements\n",
      "\n",
      "The notice may not amend the terms of a Mortgage other than those relating to where to send payments. The Master Servicer and any Servicing Agent must ensure that their staff and facilities are adequately prepared to process Servicing and accounting transactions and to respond to Borrower inquiries during the transfer transition period. The Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations must assume responsibility for responding to Borrower inquiries received after the date of such undertaking. If any Servicing or accounting problem cannot be resolved without the involvement of the Servicer that was performing the Servicing obligations, the new Servicing Agent or Master Servicer undertaking the performance of the Servicing obligations, and not the Borrower, should initiate the contact with the prior Servicer.\n",
      "\n",
      "Context 4:\n",
      "# A3-3-03, Other Servicing Arrangements (12/15/2015)\n",
      "\n",
      "## General Requirements for Subservicing Arrangements\n",
      "\n",
      "A servicer may use a subservicer only if it will not interfere with the servicer's ability to meet Fannie Mae's remitting and reporting requirements. A master servicer may not enter into new subservicing arrangements—or extend existing arrangements to include newly originated mortgages-unless both the master servicer and the subservicer are Fannie Mae- approved servicers in good standing who are able to perform the duties associated with the master servicer/subservicer arrangement. The master servicer must ensure that its written agreement with the subservicer acknowledges Fannie Mae's right to rescind its recognition of the subservicing arrangement if Fannie Mae decides to transfer the master servicer's portfolio for any reason. 114 The master servicer must confirm its existing subservicing arrangements when it submits the Lender Record Information (Form 582) each year. For additional information concerning subservicer and master servicer duties, responsibilities, and other requirements, see the Servicing Guide on Fannie Mae's website.\n",
      "\n",
      "Context 5:\n",
      "# Chapter A3-3, Third-Party Lending Functions and Servicing Arrangements\n",
      "\n",
      "Introduction This chapter explains Fannie Mae's requirements regarding the outsourcing of mortgage origination and servicing functions. It also addresses other servicing arrangements as well as the requirements related to document custody and document custodians. 105\n",
      "\n",
      "Answer the following question using the provided contexts:\n",
      "Does a lender have to perform servicing functions directly?\n"
     ]
    }
   ],
   "source": [
    "matches, prompt = get_prompt(question) \n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20504-40a5-4bad-86f1-cf2479880096",
   "metadata": {},
   "source": [
    "### Grounded Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbcf2224-69e4-4056-b76a-f007ed33f7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = vertexai.generative_models.GenerativeModel(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc023965-0e23-4d22-9cd1-f0f39947ec47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, a lender does not have to perform servicing functions directly.  Context 1 explicitly states that a lender \"may use other organizations to perform some or all of its servicing functions,\" referring to this as \"subservicing.\"  The contexts also describe the relationships between master servicers and subservicers, and the requirements for such arrangements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = llm.generate_content(prompt).text\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cad1b-18f5-4120-87e5-b6af492988ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "\n",
    "The resources created above in GCS and Vertex AI Vector Search will persist unless deleted.  The Vector Search Endpoint deployments have ongoing costs even if not used so it might be desirable to remove it here.  Uncomment lines in the following cells to remove resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a036f5a-7d73-4ac3-98ca-00a61693d698",
   "metadata": {},
   "source": [
    "Undeploy Indexes created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be79bbdf-0af6-4af4-ad16-6eda0e0c3ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/8009166674693455872\n",
      "MatchingEngineIndexEndpoint index_endpoint Undeployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploying index MatchingEngineIndexEndpoint index_endpoint: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Undeploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/1938314376998027264\n",
      "MatchingEngineIndexEndpoint index_endpoint Undeployed index. Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f6c9185d270> \n",
       "resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_tree_ah.display_name.replace('-', '_'))\n",
    "#vs_endpoint.undeploy_index(deployed_index_id = vs_index_brute_force.display_name.replace('-', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611aec36-5206-4d14-86bd-cbe62cfcb7e2",
   "metadata": {},
   "source": [
    "Delete the Vertex AI Vector Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ecf02fcd-5577-439f-8a29-a5843e67c07b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndexEndpoint : projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "MatchingEngineIndexEndpoint deleted. . Resource name: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Deleting MatchingEngineIndexEndpoint resource: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544\n",
      "Delete MatchingEngineIndexEndpoint backing LRO: projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544/operations/7011619357230891008\n",
      "MatchingEngineIndexEndpoint resource projects/1026793852137/locations/us-central1/indexEndpoints/5654176973186924544 deleted.\n"
     ]
    }
   ],
   "source": [
    "#vs_endpoint.delete(force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccbe71-7763-4514-8f65-79759fd90d18",
   "metadata": {},
   "source": [
    "Delete the indexes created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f0265db-d840-484d-987b-9a0e79d983e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndex : projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "MatchingEngineIndex deleted. . Resource name: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "Deleting MatchingEngineIndex resource: projects/1026793852137/locations/us-central1/indexes/2418270272177045504\n",
      "Delete MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/2418270272177045504/operations/3193692773127553024\n",
      "MatchingEngineIndex resource projects/1026793852137/locations/us-central1/indexes/2418270272177045504 deleted.\n",
      "Deleting MatchingEngineIndex : projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "MatchingEngineIndex deleted. . Resource name: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "Deleting MatchingEngineIndex resource: projects/1026793852137/locations/us-central1/indexes/1855742531220799488\n",
      "Delete MatchingEngineIndex backing LRO: projects/1026793852137/locations/us-central1/indexes/1855742531220799488/operations/4755315943918272512\n",
      "MatchingEngineIndex resource projects/1026793852137/locations/us-central1/indexes/1855742531220799488 deleted.\n"
     ]
    }
   ],
   "source": [
    "#vs_index_tree_ah.delete()\n",
    "#vs_index_brute_force.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536529d-e7d9-4f29-8c95-6bb0e556bb47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Delete the gcs content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5c54fe3-52b9-4cec-97cf-6032c188f9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#blobs = bucket.list_blobs(prefix = f\"{SERIES}/{EXPERIMENT}\")\n",
    "#for blob in blobs:\n",
    "#    blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc881805-3553-46f7-97f4-e7c2c20fc34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
