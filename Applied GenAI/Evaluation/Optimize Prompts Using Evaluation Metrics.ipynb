{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b052034b",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+GenAI%2FEvaluation&file=Optimize+Prompts+Using+Evaluation+Metrics.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520GenAI%2FEvaluation%2FOptimize%2520Prompts%2520Using%2520Evaluation%2520Metrics.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20GenAI/Evaluation/Optimize%20Prompts%20Using%20Evaluation%20Metrics.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d79870-678f-4fd2-8b3f-d0685103c9db",
   "metadata": {},
   "source": [
    "# Optimize Prompts Using Evaluation Metrics\n",
    "\n",
    "Prompt optimization rewrites system instructions to optimize the performance of set of prompts on one or more evaluation metrics.\n",
    "\n",
    "First it is helpful to understand the Vertex AI GenAI evaluation service as covered in this workflow: [Evaluation For GenAI](./Evaluation%20For%20GenAI.ipynb).  Evaluation is the comparison of a models output to a baseline or ground truth using a metric to quantify the performance.  Vertex AI offers pointwise metrics, pairwise metrics, and computed metrics for GenAI evaluation.  These same evalaution can be used as the optimization goal for prompt optimization - the focus of this workflow.\n",
    "\n",
    "The Vertex AI Prompt Optimization service is a tool:\n",
    "- Documentation Link: [Optimize Prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer)\n",
    "- This service provides code: [GitHub Link to .py file](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vapo_lib.py)\n",
    "    - And [example notebooks](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/prompts/prompt_optimizer) \n",
    "- The user uses the code to initialize a prompt optimization job which runs as a Vertex AI Custom Training Job\n",
    "- The inputs are:\n",
    "    - The current **System Instructions** - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#template-si)\n",
    "    - The **Prompt Template** for the sample prompts - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#template-si)\n",
    "        - if you have ground truth responses, or response from a known good model then the template can include a `{taget}` variable that maps to the `target` values in the input file\n",
    "        - if you don't have these responses you can provide the `source_model` parameter in the configuration and the optimziation job will use the model to generate responses for comaparison.\n",
    "    - A **file of input data** for each sample prompt to be used with the prompt template - [Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#prepare-sample-prompts)\n",
    "        - either a JSONL file or a CSV stored in a GCS bucket\n",
    "    - **Configuation parameters** for the job -[Documentation Link](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#configuration)\n",
    "        - Which metrics to use including custom metrics\n",
    "        - Which target and source LLM to use\n",
    "        - many more optional parameters\n",
    "- The outputs are:\n",
    "    - more here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2de9e-09fb-47a0-bbac-352b31b7dd29",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b929cf-bfd4-4046-bca9-549b1a9a2c99",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddec88e-5ed0-4cc6-af40-9fd0c37be7e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887c228-1e53-4601-97bf-6958f6805838",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc155657-fed5-4b08-92a3-ee40fe992246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform', '1.78.0'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('pandas', 'pandas')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c718e7-8fab-4c2d-bb8f-458ce8fa06bf",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e13ed9-b569-432c-88ec-9cd3a276b082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de01be-c07a-4a05-8643-7b18deefe236",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4c7c96-e263-45ba-bb2e-c59290f5b8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e48e4b-7bdf-4a72-b7ea-cbeb997f248f",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb350cfd-b8eb-4dd0-95ad-919710d8d752",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3e3fbc-aba1-4929-9eb1-2e363648db10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb2ebcc-2f90-4dfd-9d1c-c1df79a3713c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'applied-genai'\n",
    "EXPERIMENT = 'prompt-optimization'\n",
    "\n",
    "BUCKET = PROJECT_ID # change to Bucket name if not the same as the Project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53604d-523b-41d7-b458-e77cf6cbb854",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ce1a12-aa36-4c82-ba29-bac7a2cac6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library imports:\n",
    "import json, io, requests, sys, types, datetime, time\n",
    "\n",
    "# package imports\n",
    "from IPython.display import Markdown, HTML, display\n",
    "\n",
    "# vertex ai imports\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbf9029-51a5-4895-8306-9c3ae092145b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a66d53-8014-45eb-93b7-34869b959ba5",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de3fc66-5c7b-47df-a864-539d663b57ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1936d63-a30c-4408-9e3b-2acbff56c444",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimize Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4ddae-3921-433d-83e9-218f540a480a",
   "metadata": {},
   "source": [
    "### Load The Code\n",
    "\n",
    "The code is on [GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/prompt_optimizer/vapo_lib.py) as a `.py` file that is loaded in this session as a module with name `promptopt` by the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2e3041-81b5-423a-8229-6ac01531283c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 22:15:01.754682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738188901.791165 3313079 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738188901.802344 3313079 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 22:15:01.842139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "module_name = 'vapo_lib'\n",
    "url = 'https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/prompt_optimizer/vapo_lib.py'\n",
    "response = requests.get(url)\n",
    "vapo_lib = types.ModuleType(module_name)\n",
    "vapo_lib.__file__ = f'<remote>/{module_name}.py'\n",
    "sys.modules[module_name] = vapo_lib\n",
    "exec(response.text, vapo_lib.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e55328f-01c0-403e-9239-1a2aed786a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vapo_lib as prompt_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7cbfe-2399-4814-8d22-049380d4834a",
   "metadata": {},
   "source": [
    "### Define Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5f6416-ce67-4628-ad59-3868460ba0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTIONS = \"Write poems in the style requested based on the topic provided\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce11699a-de62-4797-9e02-5bbf1743cfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"Write a {type} about {topic}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547fff8-7845-438c-9da1-12db6b641612",
   "metadata": {},
   "source": [
    "Create data for the variables define in the prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d029fc9-a120-435d-9fc7-da8527ab59ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_parameters = [\n",
    "    dict(type = 'Haiku', topic = 'Lego'),\n",
    "    dict(type = 'Sonnet', topic = 'Lego'),\n",
    "    dict(type = 'Limerick', topic = 'Lego'),\n",
    "    dict(type = 'Acrostic', topic = 'Lego'),\n",
    "    dict(type = 'Ode', topic = 'Lego')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3941880-4af5-4709-99f6-09dfd8fa2b9b",
   "metadata": {},
   "source": [
    "Store the data in GCS as either JSONL or CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c7106e-5c63-431c-956e-b06240ed5a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = gcs.bucket(BUCKET)\n",
    "blob = bucket.blob(f'{SERIES}/{EXPERIMENT}/prompt_parameters.jsonl')\n",
    "with io.StringIO() as jsonl_file:\n",
    "    for item in prompt_parameters:\n",
    "        json.dump(item, jsonl_file)\n",
    "        jsonl_file.write('\\n')\n",
    "    blob.upload_from_string(jsonl_file.getvalue(), content_type = 'application/jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd1468-7e5d-43dd-a08b-6f63d55a268f",
   "metadata": {},
   "source": [
    "### Define Inputs Parameters And Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd185b9f-c496-4aae-8af6-1f43cc289b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOURCE_MODEL = \"gemini-1.5-flash-001\" # or provide ground truth\n",
    "TARGET_MODEL = \"gemini-1.5-flash-002\" # the model for which the optimized system instructions are created for\n",
    "OPTIMIZATION_MODE = \"instruction\" # choices are instuction, demonstration, instruction_and_demo\n",
    "EVAL_METRICS = ['coherence', 'fluency'] # https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer#supported-evaluation-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7e651ac-a58d-4121-8057-bb5c3864f3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_opt.is_run_target_required(\n",
    "    eval_metric_types = EVAL_METRICS,\n",
    "    source_model = SOURCE_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d63e6a2-f60c-4e05-9ed4-127458824f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_opt.validate_prompt_and_data(\n",
    "    template = '\\n'.join([SYSTEM_INSTRUCTIONS, PROMPT_TEMPLATE]),\n",
    "    dataset_path = f'gs://{bucket.name}/{blob.name}',\n",
    "    placeholder_to_content = '{}',\n",
    "    label_enforced = prompt_opt.is_run_target_required(\n",
    "        eval_metric_types = EVAL_METRICS,\n",
    "        source_model = SOURCE_MODEL\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedf305-dd6b-4695-b19e-2aefac4696c8",
   "metadata": {},
   "source": [
    "### Run Optimization Job On Vertex AI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2b84469-a0e8-4717-867c-ce9107d3d282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Job display name: lego_lyrics_2025-01-29T22:37:33\n",
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/1026793852137/locations/us-central1/customJobs/8303196768523255808\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/1026793852137/locations/us-central1/customJobs/8303196768523255808')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8303196768523255808?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "job_name = 'lego_lyrics_' + datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "vertex_job = prompt_opt.run_apd(\n",
    "    config = dict(\n",
    "        project = PROJECT_ID,\n",
    "        system_instruction = SYSTEM_INSTRUCTIONS,\n",
    "        prompt_template = PROMPT_TEMPLATE,\n",
    "        target_model = TARGET_MODEL,\n",
    "        target_model_location = REGION, \n",
    "        eval_metrics_types = EVAL_METRICS,\n",
    "        eval_metrics_weights = [.5, .5],\n",
    "        aggregation_type = 'weighted_sum',\n",
    "        source_model = SOURCE_MODEL,\n",
    "        optimization_mode = OPTIMIZATION_MODE,\n",
    "        input_data_path = f'gs://{bucket.name}/{blob.name}',\n",
    "        output_path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}'\n",
    "    ),\n",
    "    bucket_uri = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}',\n",
    "    display_name = job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bae3bb4-98d9-4710-984b-f6331d38cbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8303196768523255808',\n",
       " 'lego_lyrics_2025-01-29T22:37:33',\n",
       " 'projects/1026793852137/locations/us-central1/customJobs/8303196768523255808')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.name, vertex_job.display_name, vertex_job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f1349b-f06c-467a-a5fb-1bb42f4c5896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n",
      "Job state: 3, checking again in 30 seconds...\n"
     ]
    }
   ],
   "source": [
    "while vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_PENDING or vertex_job.state == aiplatform.gapic.JobState.JOB_STATE_RUNNING:\n",
    "    print(f\"Job state: {vertex_job.state}, checking again in 30 seconds...\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02cfd7b8-a65d-45cf-b3f1-134ce12fd3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB_STATE_SUCCEEDED'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_job.state.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe72cc-6db1-4ecc-b75f-aebc506d0d0f",
   "metadata": {},
   "source": [
    "### Review The Optimized Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92a4c0-3ff4-4a73-9ff4-682c31151e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "statmike-mlops-349915/applied-genai/prompt-optimization/lego_lyrics_2025-01-29T22:37:33/instruction/optimized_results.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1533379c-3ae9-4fd9-8319-1bcbce5e5c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = json.loads(\n",
    "    bucket.blob(f'{SERIES}/{EXPERIMENT}/{job_name}/instruction/optimized_results.json').download_as_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca62b986-1a16-478e-ab07-cf33b6aa451e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 0,\n",
       " 'metrics': {'coherence/mean': 4.6,\n",
       "  'fluency/mean': 4.4,\n",
       "  'composite_metric/mean': 4.5},\n",
       " 'prompt': 'Write poems in the style requested based on the topic provided'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f068ab-08ea-445b-abd8-6357c0824edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159336d-a49d-49ca-92cf-961d1000d8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ddddff-47ab-4c44-b8b0-d89ac0ff46b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fafdc1e-9472-47ea-add5-dbe24e517d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Review The Evaluation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df3ce2f6-a92b-4e37-a13f-c9f72032a523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_ui = prompt_opt.ResultsUI(path = f'gs://{bucket.name}/{SERIES}/{EXPERIMENT}/{job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6de0fe5-79fe-47a0-8cd0-16881c6a8828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .scrollable {\n",
       "    width: 100%;\n",
       "    height: 80px;\n",
       "    overflow-y: auto;\n",
       "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
       "  }\n",
       "  tr:nth-child(odd) {\n",
       "    background: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "  tr:nth-child(even) {\n",
       "    background-color: var(--colab-primary-surface-color);\n",
       "  }\n",
       "  th {\n",
       "    background-color: var(--colab-highlighted-surface-color);\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536c47656c604da1806e43681a0c62fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select Run:'), Dropdown(layout=Layout(width='200px'), options=('gs://statmike-mlop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df_html = \"\"\"\n",
    "<style>\n",
    "  .scrollable {\n",
    "    width: 100%;\n",
    "    height: 80px;\n",
    "    overflow-y: auto;\n",
    "    overflow-x: hidden;  /* Hide horizontal scrollbar */\n",
    "  }\n",
    "  tr:nth-child(odd) {\n",
    "    background: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "  tr:nth-child(even) {\n",
    "    background-color: var(--colab-primary-surface-color);\n",
    "  }\n",
    "  th {\n",
    "    background-color: var(--colab-highlighted-surface-color);\n",
    "  }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(results_df_html))\n",
    "display(results_ui.get_container())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4534a86-860f-4831-8899-dddff6957679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
